{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOcdkPdK3QPX",
        "outputId": "555775fa-35bc-47c0-f044-aef932c1da8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]], shape=(5, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def one_hot_encode_tensorflow(text, vocab):\n",
        "    \"\"\"\n",
        "    Encodes text tokens into one-hot vectors using TensorFlow.\n",
        "\n",
        "    Args:\n",
        "        text: A list of tokens (words) in the text.\n",
        "        vocab: A dictionary mapping words to their indices in the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        A tensor of shape (len(text), vocab_size) containing one-hot encoded vectors.\n",
        "    \"\"\"\n",
        "    vocab_size = len(vocab)\n",
        "    indices = [vocab[word] for word in text if word in vocab]\n",
        "    encoded_text = tf.one_hot(indices, depth=vocab_size, dtype=tf.float32)\n",
        "    return encoded_text\n",
        "\n",
        "# Example usage\n",
        "text = [\"hello\", \"world\", \"how\", \"are\", \"you\"]\n",
        "word_to_ix = {word: i for i, word in enumerate(text)}\n",
        "encoded_text = one_hot_encode_tensorflow(text, word_to_ix)\n",
        "print(encoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define a simple list of words\n",
        "vocab = ['hello', 'world', 'its', 'a', 'beautiful', 'day']\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# Function to convert words to one-hot vectors\n",
        "def one_hot_encode(word, word_to_ix, vocab_size):\n",
        "    vec = torch.zeros(vocab_size)\n",
        "    vec[word_to_ix[word]] = 1\n",
        "    return vec\n",
        "\n",
        "# Example usage\n",
        "one_hot_hello = one_hot_encode('day', word_to_ix, len(vocab))\n",
        "print(one_hot_hello)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJvxPPP25jZ9",
        "outputId": "d71a65fe-8c11-4478-ed1f-cfe42a3b67e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple list of words\n",
        "vocab = ['hello', 'world']\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# Function to convert words to one-hot vectors\n",
        "def one_hot_encode(word, word_to_ix, vocab_size):\n",
        "    vec = tf.one_hot(word_to_ix[word], depth=vocab_size)\n",
        "    return vec\n",
        "\n",
        "# Example usage\n",
        "one_hot_hello = one_hot_encode('hello', word_to_ix, len(vocab))\n",
        "print(one_hot_hello)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPYniBxH3V0F",
        "outputId": "cfeb7184-28fe-42f8-e5f8-afee456a1f08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple list of words\n",
        "vocab = ['hello', 'world']\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# Embedding layer\n",
        "embedding_dim = 5\n",
        "embeddings = nn.Embedding(len(vocab), embedding_dim)\n",
        "print(word_to_ix)\n",
        "print(embeddings)\n",
        "\n",
        "# Example usage\n",
        "hello_idx = torch.tensor([word_to_ix['hello']], dtype=torch.long)\n",
        "hello_embed = embeddings(hello_idx)\n",
        "print(hello_embed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCc3up5o3oWN",
        "outputId": "96278948-4dfd-49eb-dbaa-4fc2f2ae3c23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hello': 0, 'world': 1}\n",
            "Embedding(2, 5)\n",
            "tensor([[-2.1952, -0.2398,  0.0591, -2.0666, -0.3344]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple list of words\n",
        "vocab = ['hello', 'world', 'how', 'are', 'you']\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# Embedding layer\n",
        "embedding_dim = 5\n",
        "embeddings = nn.Embedding(len(vocab), embedding_dim)\n",
        "\n",
        "# Example usage\n",
        "hello_idx = torch.tensor([word_to_ix['hello']], dtype=torch.long)\n",
        "hello_embed = embeddings(hello_idx)\n",
        "print(hello_embed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUdY6gxf4gd7",
        "outputId": "fc6e6ac3-3f11-4380-a431-46ebed1de6fb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3312, -0.9726, -1.6614, -0.4809, -0.4103]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple list of words\n",
        "vocab = ['hello', 'world', 'how', 'are', 'you']\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# Embedding layer\n",
        "embedding_dim = 5\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(vocab), output_dim=embedding_dim)\n",
        "\n",
        "# Example usage\n",
        "hello_idx = tf.constant([word_to_ix['hello']])\n",
        "hello_embed = embeddings(hello_idx)\n",
        "print(hello_embed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdfXqEPb56UO",
        "outputId": "0e6d028f-c170-4d98-aa7c-0658c229f849"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ 0.04670728  0.04406584  0.04991266 -0.0131113   0.00373048]], shape=(1, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = ['hello', 'world', 'how', 'are', 'you']\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# Function to convert words to integers\n",
        "def integer_encode(word, word_to_ix):\n",
        "    return word_to_ix[word]\n",
        "\n",
        "# Example usage\n",
        "hello_int = integer_encode('you', word_to_ix)\n",
        "print(hello_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkLByrAY87u8",
        "outputId": "c09fd8c5-3e5a-4b0b-fa51-f89d9345a39d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Function to convert word to character-level one-hot vectors\n",
        "def char_one_hot_encode(word, char_to_ix, vocab_size):\n",
        "    char_vectors = []\n",
        "    for char in word:\n",
        "        vec = torch.zeros(vocab_size)\n",
        "        vec[char_to_ix[char]] = 1\n",
        "        char_vectors.append(vec)\n",
        "    return torch.stack(char_vectors)\n",
        "\n",
        "# Define characters and create index\n",
        "chars = list(set('hello world'))\n",
        "char_to_ix = {char: i for i, char in enumerate(chars)}\n",
        "\n",
        "# Example usage\n",
        "char_vectors = char_one_hot_encode('hello', char_to_ix, len(chars))\n",
        "print(char_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBiUAf3C9apt",
        "outputId": "8fa7ed83-4959-4c4d-c006-b1d00b5369dc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Function to convert word to character-level one-hot vectors\n",
        "def char_one_hot_encode(word, char_to_ix, vocab_size):\n",
        "    char_vectors = []\n",
        "    for char in word:\n",
        "        vec = tf.one_hot(char_to_ix[char], depth=vocab_size)\n",
        "        char_vectors.append(vec)\n",
        "    return tf.stack(char_vectors)\n",
        "\n",
        "# Define characters and create index\n",
        "chars = list(set('hello world'))\n",
        "char_to_ix = {char: i for i, char in enumerate(chars)}\n",
        "\n",
        "# Example usage\n",
        "char_vectors = char_one_hot_encode('hello', char_to_ix, len(chars))\n",
        "print(char_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVD2UUnI98rg",
        "outputId": "d85c6d4d-a641-4b24-e2a7-b1313346b4fa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]], shape=(5, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n",
        "\n",
        "# Define the tokenizer\n",
        "tokenizer = Tokenizer(models.BPE())\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
        "tokenizer.decoder = decoders.ByteLevel()\n",
        "\n",
        "# Training data\n",
        "training_data = [\"hello world\"]\n",
        "\n",
        "# Trainer\n",
        "trainer = trainers.BpeTrainer(vocab_size=50, min_frequency=2)\n",
        "\n",
        "# Train the tokenizer\n",
        "tokenizer.train_from_iterator(training_data, trainer)\n",
        "\n",
        "# Encode\n",
        "encoded = tokenizer.encode(\"hello world\")\n",
        "print(encoded.ids)\n",
        "print(encoded.tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jctV3SoN-Kei",
        "outputId": "c2a9e706-ccf6-4761-c631-8a91220a5318"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7, 2, 1, 3, 3, 4, 7, 6, 4, 5, 3, 0]\n",
            "['Ġ', 'h', 'e', 'l', 'l', 'o', 'Ġ', 'w', 'o', 'r', 'l', 'd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n",
        "\n",
        "# Define the tokenizer using Byte-Pair Encoding (BPE)\n",
        "tokenizer = Tokenizer(models.BPE())\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
        "tokenizer.decoder = decoders.ByteLevel()\n",
        "\n",
        "# Training data\n",
        "training_data = [\"hello world\"]\n",
        "\n",
        "# Trainer setup\n",
        "trainer = trainers.BpeTrainer(vocab_size=50, min_frequency=2)\n",
        "\n",
        "# Train the tokenizer\n",
        "tokenizer.train_from_iterator(training_data, trainer)\n",
        "\n",
        "# Encode the text\n",
        "encoded = tokenizer.encode(\"hello world\")\n",
        "print(\"Encoded IDs:\", encoded.ids)\n",
        "print(\"Encoded tokens:\", encoded.tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeSurwjU-tLy",
        "outputId": "7e09f1d4-f653-4116-d591-a7f4f6369b86"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded IDs: [7, 2, 1, 3, 3, 4, 7, 6, 4, 5, 3, 0]\n",
            "Encoded tokens: ['Ġ', 'h', 'e', 'l', 'l', 'o', 'Ġ', 'w', 'o', 'r', 'l', 'd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n",
        "\n",
        "# Define the tokenizer using Byte-Pair Encoding (BPE)\n",
        "tokenizer = Tokenizer(models.BPE())\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
        "tokenizer.decoder = decoders.ByteLevel()\n",
        "\n",
        "# Training data\n",
        "training_data = [\"hello world\"]\n",
        "\n",
        "# Trainer setup\n",
        "trainer = trainers.BpeTrainer(vocab_size=50, min_frequency=2)\n",
        "\n",
        "# Train the tokenizer\n",
        "tokenizer.train_from_iterator(training_data, trainer)\n",
        "\n",
        "# Encode the text\n",
        "encoded = tokenizer.encode(\"hello world\")\n",
        "print(\"Encoded IDs:\", encoded.ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_K9zwUiCEsU",
        "outputId": "6621b87c-abbf-49bd-c115-ca8240605912"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded IDs: [7, 2, 1, 3, 3, 4, 7, 6, 4, 5, 3, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example text\n",
        "text = \"unaffable\"\n",
        "\n",
        "# Encode the text using WordPiece encoding\n",
        "encoded = tokenizer.encode(text, add_special_tokens=False)\n",
        "encoded_tokens = tokenizer.convert_ids_to_tokens(encoded)\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "encoded_tensor = torch.tensor(encoded)\n",
        "\n",
        "print(\"Encoded IDs:\", encoded)\n",
        "print(\"Encoded Tokens:\", encoded_tokens)\n",
        "print(\"Encoded Tensor:\", encoded_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjRmED9LCFSD",
        "outputId": "54c053c8-05f1-4a96-e712-e5df5b248d79"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded IDs: [14477, 20961, 3468]\n",
            "Encoded Tokens: ['una', '##ffa', '##ble']\n",
            "Encoded Tensor: tensor([14477, 20961,  3468])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example text\n",
        "text = \"unaffable\"\n",
        "\n",
        "# Encode the text using WordPiece encoding\n",
        "encoded = tokenizer.encode(text, add_special_tokens=False)\n",
        "encoded_tokens = tokenizer.convert_ids_to_tokens(encoded)\n",
        "\n",
        "# Convert to TensorFlow tensor\n",
        "encoded_tensor = tf.constant(encoded)\n",
        "\n",
        "print(\"Encoded IDs:\", encoded)\n",
        "print(\"Encoded Tokens:\", encoded_tokens)\n",
        "print(\"Encoded Tensor:\", encoded_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhuJMkxQCpKB",
        "outputId": "40bc0b37-aca6-476d-8e84-f9f33ee65719"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded IDs: [14477, 20961, 3468]\n",
            "Encoded Tokens: ['una', '##ffa', '##ble']\n",
            "Encoded Tensor: tf.Tensor([14477 20961  3468], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Sample data\n",
        "text = 'unaffable'\n",
        "\n",
        "# Create a vocabulary (usually learned from a larger corpus)\n",
        "vocab = ['un', 'aff', 'able', 'a', 'affable']\n",
        "vocab_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "# WordPiece Encoding\n",
        "def wordpiece_tokenize(text, vocab):\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        for j in range(len(text), i, -1):\n",
        "            if text[i:j] in vocab:\n",
        "                tokens.append(text[i:j])\n",
        "                i = j - 1\n",
        "                break\n",
        "        i += 1\n",
        "    return tokens\n",
        "\n",
        "# Encode text\n",
        "wordpiece_encoded = wordpiece_tokenize(text, vocab)\n",
        "\n",
        "# Convert to indices\n",
        "wordpiece_indices = [vocab_to_index[token] for token in wordpiece_encoded]\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "wordpiece_tensor = torch.tensor(wordpiece_indices, dtype=torch.long)\n",
        "print(wordpiece_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0fsCOZgCrRk",
        "outputId": "3afca1fe-546c-462b-e967-45b8c3c1133f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 4])\n"
          ]
        }
      ]
    }
  ]
}