{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: ANNs\n",
    "### LECTURE: Multi-output ANN (iris dataset)\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBzskQUd2RK0"
   },
   "source": [
    "# Import and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MU7rvmWuhjud"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset (comes with seaborn)\n",
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "### NOTE: As of Jan 2024, there seems to be an error with colab accessing the seaborn sample data.\n",
    "# If the code above gives an error, use the following two lines instead.\n",
    "#import pandas as pd\n",
    "#iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "\n",
    "\n",
    "# check out the first few lines of data\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KVAz6ymFpPYn"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# some plots to show the data\n",
    "sns.pairplot(iris, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJPkH6Bfh01_"
   },
   "outputs": [],
   "source": [
    "# organize the data\n",
    "\n",
    "# convert from pandas dataframe to tensor\n",
    "data = torch.tensor( iris[iris.columns[0:4]].values ).float()\n",
    "\n",
    "# transform species to number\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "# labels[iris.species=='setosa'] = 0 # don't need!\n",
    "labels[iris.species=='versicolor'] = 1\n",
    "labels[iris.species=='virginica'] = 2\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwusZlcu2VVS"
   },
   "source": [
    "# Create the ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0JMIGb1iV_9"
   },
   "outputs": [],
   "source": [
    "# model architecture\n",
    "ANNiris = nn.Sequential(\n",
    "    nn.Linear(4,64),   # input layer\n",
    "    nn.ReLU(),         # activation\n",
    "    nn.Linear(64,64),  # hidden layer\n",
    "    nn.ReLU(),         # activation\n",
    "    nn.Linear(64,3),   # output layer\n",
    "      )\n",
    "\n",
    "# loss function\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPJl5Fzw2Xgy"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVD1nFTli7TO"
   },
   "outputs": [],
   "source": [
    "numepochs = 1000\n",
    "\n",
    "# initialize losses\n",
    "losses = torch.zeros(numepochs)\n",
    "ongoingAcc = []\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # forward pass\n",
    "  yHat = ANNiris(data)\n",
    "\n",
    "  # compute loss\n",
    "  loss = lossfun(yHat,labels)\n",
    "  losses[epochi] = loss\n",
    "\n",
    "  # backprop\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # compute accuracy\n",
    "  matches = torch.argmax(yHat,axis=1) == labels # booleans (false/true)\n",
    "  matchesNumeric = matches.float()              # convert to numbers (0/1)\n",
    "  accuracyPct = 100*torch.mean(matchesNumeric)  # average and x100\n",
    "  ongoingAcc.append( accuracyPct )              # add to list of accuracies\n",
    "\n",
    "\n",
    "\n",
    "# final forward pass\n",
    "predictions = ANNiris(data)\n",
    "\n",
    "predlabels = torch.argmax(predictions,axis=1)\n",
    "totalacc = 100*torch.mean((predlabels == labels).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CV3d45izbkB"
   },
   "outputs": [],
   "source": [
    "torch.argmax(yHat,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xa3RWuZ2adq"
   },
   "source": [
    "# Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYouZAY4i3jM"
   },
   "outputs": [],
   "source": [
    "# report accuracy\n",
    "print('Final accuracy: %g%%' %totalacc)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(13,4))\n",
    "\n",
    "ax[0].plot(losses.detach())\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_title('Losses')\n",
    "\n",
    "ax[1].plot(ongoingAcc)\n",
    "ax[1].set_ylabel('accuracy')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].set_title('Accuracy')\n",
    "plt.show()\n",
    "# run training again to see whether this performance is consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "St6NI4qBk4tO"
   },
   "outputs": [],
   "source": [
    "# confirm that all model predictions sum to 1, but only when converted to softmax\n",
    "sm = nn.Softmax(1)\n",
    "torch.sum(sm(yHat),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gB8-aMAF_xIQ"
   },
   "outputs": [],
   "source": [
    "# plot the raw model outputs\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.plot(yHat.detach(),'s-',markerfacecolor='w')\n",
    "plt.xlabel('Stimulus number')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend(['setosa','versicolor','virginica'])\n",
    "plt.show()\n",
    "\n",
    "# try it again without the softmax!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvLH4h6ek5Ax"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7MKj66sk5DY"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIXi3fONIKVA"
   },
   "outputs": [],
   "source": [
    "# 1) When the loss does not reach an asymptote, it's a good idea to train the model for more epochs. Increase the number of\n",
    "#    epochs until the plot of the losses seems to hit a \"floor\" (that's a statistical term for being as small as possible).\n",
    "#\n",
    "# 2) We used a model with 64 hidden units. Modify the code to have 16 hidden units. How does this model perform? If there\n",
    "#    is a decrease in accuracy, is that decrease distributed across all three iris types, or does the model learn some\n",
    "#    iris types and not others?\n",
    "#\n",
    "# 3) Write code to compute three accuracy scores, one for each iris type. In real DL projects, category-specific accuracies\n",
    "#    are often more informative than the aggregated accuracy.\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
